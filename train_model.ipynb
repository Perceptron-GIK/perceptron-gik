{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GIK Character Prediction Model\n",
        "\n",
        "Train a model to predict keyboard characters from IMU sensor data.\n",
        "\n",
        "Best config: LSTM + Focal Loss (~37% test accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch 2.9.1+cpu | Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add project root to path\n",
        "PROJECT_ROOT = os.path.dirname(os.path.abspath('__file__'))\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "from pretraining import preprocess_and_export, preprocess_multiple_sources, load_preprocessed_dataset, export_dataset_to_csv\n",
        "from src.pre_processing.alignment import INDEX_TO_CHAR, CHAR_TO_INDEX, NUM_CLASSES\n",
        "from src.pre_processing.reduce_dim import reduce_dim\n",
        "from ml.models.basic_nn import create_model_from_dataset, GIKTrainer, decode_predictions\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "print(f\"PyTorch {torch.__version__} | Device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data dir: data_right_all\n",
            "Keyboard files: None\n",
            "Left IMU files: None\n",
            "Right IMU files: None\n",
            "Model: lstm\n",
            "Seq length: 10\n"
          ]
        }
      ],
      "source": [
        "# Data paths - Using data_hazel_2 with multiple sources\n",
        "DATA_DIR = \"data_right_all\"\n",
        "\n",
        "# Multiple data sources (paired keyboard + IMU files)\n",
        "KEYBOARD_FILES = None\n",
        "LEFT_FILES = None\n",
        "RIGHT_FILES = None  # Set to list of files if available\n",
        "\n",
        "PROCESSED_DATA_PATH = os.path.join(DATA_DIR, \"processed_dataset.pt\")\n",
        "\n",
        "# Training config - OPTIMIZED (best: LSTM + Focal Loss ~37% test acc)\n",
        "CONFIG = {\n",
        "    'max_seq_length': 10,\n",
        "    'hidden_dim': 128,\n",
        "    'num_layers': 2,\n",
        "    'dropout': 0.5,  # Increased for regularization\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 5e-4,\n",
        "    'weight_decay': 1e-3,  # L2 regularization\n",
        "    'epochs': 100,\n",
        "    'early_stopping': 20,\n",
        "    # Model: 'lstm' (best) | 'transformer' | 'attention_lstm' | 'gru' | 'rnn' | 'cnn'\n",
        "    'model_type': 'lstm',\n",
        "    'bidirectional': True,  # For LSTM/GRU\n",
        "    'use_focal_loss': True,  # Handles class imbalance\n",
        "    'focal_gamma': 2.0,\n",
        "}\n",
        "\n",
        "print(f\"Data dir: {DATA_DIR}\")\n",
        "print(f\"Keyboard files: {KEYBOARD_FILES}\")\n",
        "print(f\"Left IMU files: {LEFT_FILES}\")\n",
        "print(f\"Right IMU files: {RIGHT_FILES}\")\n",
        "print(f\"Model: {CONFIG['model_type']}\")\n",
        "print(f\"Seq length: {CONFIG['max_seq_length']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess and combine multiple data sources\n",
        "metadata = preprocess_multiple_sources(\n",
        "    data_dir=DATA_DIR,\n",
        "    keyboard_files=KEYBOARD_FILES,\n",
        "    left_files=LEFT_FILES,\n",
        "    right_files=RIGHT_FILES,\n",
        "    output_path=PROCESSED_DATA_PATH,\n",
        "    max_seq_length=CONFIG['max_seq_length'],\n",
        "    normalize=True,\n",
        "    apply_filtering=True\n",
        ")\n",
        "print(f\"\\nTotal Samples: {metadata['num_samples']} | Input dim: {metadata['input_dim']} | Sources: {metadata['num_sources']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to CSV for inspection (optional)\n",
        "export_dataset_to_csv(PROCESSED_DATA_PATH, DATA_DIR, include_features=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature dimension reduced from 59 to 16\n"
          ]
        }
      ],
      "source": [
        "DIM_RED_OUTPUT = os.path.join(DATA_DIR, \"dim_red_output.pt\")\n",
        "\n",
        "# Ideally pass the metadata from preprocessing instead of manually setting it here but this avoids having to rerun the preprocessing step\n",
        "HAS_LEFT = False\n",
        "HAS_RIGHT = True\n",
        "\n",
        "dims = reduce_dim(PROCESSED_DATA_PATH, \"active-imu\", HAS_LEFT, HAS_RIGHT, DIM_RED_OUTPUT)\n",
        "print(f\"Feature dimension reduced from {dims['dim_bef']} to {dims['dim_aft']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset & Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/c/users/huiqi/documents/icl/modules/[SP] 114 AML Devices/perceptron-gik/pretraining.py:544: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  self.samples = data['samples']\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "too many indices for tensor of dimension 3",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_preprocessed_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDIM_RED_OUTPUT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples | Input dim: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39minput_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create model\u001b[39;00m\n",
            "File \u001b[0;32m/mnt/c/users/huiqi/documents/icl/modules/[SP] 114 AML Devices/perceptron-gik/pretraining.py:394\u001b[0m, in \u001b[0;36mload_preprocessed_dataset\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_preprocessed_dataset\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreprocessedGIKDataset\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Load a preprocessed dataset from disk.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m        PreprocessedGIKDataset instance\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPreprocessedGIKDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/c/users/huiqi/documents/icl/modules/[SP] 114 AML Devices/perceptron-gik/pretraining.py:544\u001b[0m, in \u001b[0;36mPreprocessedGIKDataset.__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m    path: Path to preprocessed .pt file\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(path, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msamples\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    545\u001b[0m labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    546\u001b[0m prev_labels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_labels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 3"
          ]
        }
      ],
      "source": [
        "dataset = load_preprocessed_dataset(PROCESSED_DATA_PATH)\n",
        "print(f\"Dataset: {len(dataset)} samples | Input dim: {dataset.input_dim}\")\n",
        "\n",
        "# Create model\n",
        "model = create_model_from_dataset(\n",
        "    dataset,\n",
        "    model_type=CONFIG['model_type'],\n",
        "    hidden_dim=CONFIG['hidden_dim'],\n",
        "    num_layers=CONFIG['num_layers'],\n",
        "    dropout=CONFIG['dropout'],\n",
        ")\n",
        "\n",
        "# Print model architecture\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Model architecture\")\n",
        "print(\"=\" * 60)\n",
        "print(model)\n",
        "print(\"=\" * 60)\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = GIKTrainer(\n",
        "    model=model,\n",
        "    dataset=dataset,\n",
        "    batch_size=CONFIG['batch_size'],\n",
        "    learning_rate=CONFIG['learning_rate'],\n",
        "    device=DEVICE,\n",
        "    use_focal_loss=CONFIG.get('use_focal_loss', False),\n",
        "    focal_gamma=CONFIG.get('focal_gamma', 2.0)\n",
        ")\n",
        "\n",
        "history = trainer.train(\n",
        "    epochs=CONFIG['epochs'],\n",
        "    early_stopping_patience=CONFIG['early_stopping']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "axes[0].plot(history['train_loss'], label='Train')\n",
        "axes[0].plot(history['val_loss'], label='Val')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "axes[0].set_title('Loss')\n",
        "\n",
        "axes[1].plot(history['train_acc'], label='Train')\n",
        "axes[1].plot(history['val_acc'], label='Val')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].set_title('Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on validation set\n",
        "val_loss, val_acc = trainer.validate()\n",
        "print(f\"Validation Loss: {val_loss:.4f} | Validation Accuracy: {val_acc:.2%}\")\n",
        "print()\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc = trainer.evaluate_test()\n",
        "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to display predictions\n",
        "def show_predictions(data_subset, subset_name, max_samples=50):\n",
        "    \"\"\"Show predictions for a dataset subset.\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    results = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx in range(len(data_subset)):\n",
        "            x, y_true = data_subset[idx]\n",
        "            x = x.unsqueeze(0).to(DEVICE)\n",
        "            y_pred = model(x)\n",
        "            \n",
        "            true_char = INDEX_TO_CHAR.get(y_true.argmax().item(), '?')\n",
        "            pred_char = INDEX_TO_CHAR.get(y_pred.argmax().item(), '?')\n",
        "            \n",
        "            is_correct = true_char == pred_char\n",
        "            if is_correct:\n",
        "                correct += 1\n",
        "            \n",
        "            results.append((true_char, pred_char, is_correct))\n",
        "    \n",
        "    # Print header\n",
        "    print(f\"=== {subset_name} Predictions ({correct}/{len(results)} correct = {correct/len(results):.2%}) ===\")\n",
        "    print()\n",
        "    \n",
        "    # Show samples (up to max_samples)\n",
        "    n_show = min(max_samples, len(results))\n",
        "    for i, (true_char, pred_char, is_correct) in enumerate(results[:n_show]):\n",
        "        # Display special chars nicely\n",
        "        true_disp = {'\\n': 'ENTER', ' ': 'SPACE', '\\t': 'TAB', '\\b': 'BKSP'}.get(true_char, true_char)\n",
        "        pred_disp = {'\\n': 'ENTER', ' ': 'SPACE', '\\t': 'TAB', '\\b': 'BKSP'}.get(pred_char, pred_char)\n",
        "        match = '✓' if is_correct else '✗'\n",
        "        print(f\"{match} True: {true_disp:8} | Pred: {pred_disp:8}\")\n",
        "    \n",
        "    if len(results) > n_show:\n",
        "        print(f\"... and {len(results) - n_show} more samples\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show validation predictions\n",
        "show_predictions(trainer.val_dataset, 'Validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show test predictions\n",
        "show_predictions(trainer.test_dataset, 'Test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "# Refined coordinates for letters and digits, trying to map out the real QWERTY keyboard layout\n",
        "KEY_COORDS = {\n",
        "\n",
        "    '1': (0.0, 0.0), '2': (1.0, 0.0), '3': (2.0, 0.0), '4': (3.0, 0.0), '5': (4.0, 0.0), '6': (5.0, 0.0), '7': (6.0, 0.0), '8': (7.0, 0.0), '9': (8.0, 0.0), '0': (9.0, 0.0),\n",
        "\n",
        "    'q': (0.5, 1.0), 'w': (1.5, 1.0), 'e': (2.5, 1.0), 'r': (3.5, 1.0), 't': (4.5, 1.0), 'y': (5.5, 1.0), 'u': (6.5, 1.0), 'i': (7.5, 1.0), 'o': (8.5, 1.0), 'p': (9.5, 1.0),\n",
        "\n",
        "    'a': (0.8, 2.0), 's': (1.8, 2.0), 'd': (2.8, 2.0), 'f': (3.8, 2.0), 'g': (4.8, 2.0), 'h': (5.8, 2.0), 'j': (6.8, 2.0), 'k': (7.8, 2.0), 'l': (8.8, 2.0),\n",
        "\n",
        "    'z': (1.3, 3.0), 'x': (2.3, 3.0), 'c': (3.3, 3.0), 'v': (4.3, 3.0), 'b': (5.3, 3.0), 'n': (6.3, 3.0), 'm': (7.3, 3.0),\n",
        "}\n",
        "\n",
        "# Approximate coordinates for specials so they sit in plausible places\n",
        "SPECIAL_COORDS = {\n",
        "    '\\n': (12.0, 2.0),  # enter to the right of L\n",
        "    '\\b': (12.0, 0.0),  # backspace to the right of P\n",
        "    '\\t': (-0.5, 1.0),  # tab to the left of Q\n",
        "}\n",
        "\n",
        "SPACE_ANCHORS = [ # Make space bar long\n",
        "    (3.3, 4.0),  # under C\n",
        "    (4.3, 4.0),  # under v\n",
        "    (5.3, 4.0),  # under B\n",
        "    (6.3, 4.0),  # under N\n",
        "    (7.3, 4.0),  # under M\n",
        "\n",
        "]\n",
        "\n",
        "ALL_CHARS = [INDEX_TO_CHAR[i] for i in range(40)]\n",
        "\n",
        "FULL_COORDS = {}\n",
        "for ch in ALL_CHARS:\n",
        "    if ch in KEY_COORDS:\n",
        "        FULL_COORDS[ch] = KEY_COORDS[ch]\n",
        "    elif ch in SPECIAL_COORDS:\n",
        "        FULL_COORDS[ch] = SPECIAL_COORDS[ch]\n",
        "    elif ch == ' ':\n",
        "        # handledvia SPACE_ANCHORS below\n",
        "        continue\n",
        "    else:\n",
        "        # generic fallback (e.g., if something unexpected appears)\n",
        "        FULL_COORDS[ch] = (5.3, 4.0) # default to spacebar center\n",
        "\n",
        "\n",
        "def key_distance(ch1, ch2):\n",
        "    \"\"\"\n",
        "    Distance between two keys.\n",
        "    For space (' '), use the minimum distance to its multiple anchor points\n",
        "    to mimic a long bar; other keys use their single coordinate.\n",
        "    \"\"\"\n",
        "    def coords(ch):\n",
        "        if ch == ' ':\n",
        "            return SPACE_ANCHORS\n",
        "        else:\n",
        "            return [FULL_COORDS[ch]]\n",
        "\n",
        "    pts1 = coords(ch1)\n",
        "    pts2 = coords(ch2)\n",
        "\n",
        "    d_min = float('inf')\n",
        "    for (x1, y1) in pts1:\n",
        "        for (x2, y2) in pts2:\n",
        "            d = ((x1 - x2)**2 + (y1 - y2)**2)**0.5\n",
        "            if d < d_min:\n",
        "                d_min = d\n",
        "    return d_min\n",
        "\n",
        "\n",
        "def make_display_label(c):\n",
        "    if c == ' ':\n",
        "        return 'SP'\n",
        "    elif c == '\\n':\n",
        "        return 'ENT'\n",
        "    elif c == '\\b':\n",
        "        return 'BS'\n",
        "    elif c == '\\t':\n",
        "        return 'TAB'\n",
        "    else:\n",
        "        return c\n",
        "\n",
        "\n",
        "def compute_confusion_matrix_40x40(data_subset, model, device):\n",
        "    \"\"\"Return 40x40 confusion matrix in original index order.\"\"\"\n",
        "    model.eval()\n",
        "    y_true_list = []\n",
        "    y_pred_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in range(len(data_subset)):\n",
        "            x, y_true = data_subset[idx]\n",
        "            x = x.unsqueeze(0).to(device)\n",
        "            y_pred = model(x)\n",
        "\n",
        "            y_true_list.append(y_true.argmax().item())\n",
        "            y_pred_list.append(y_pred.argmax().item())\n",
        "\n",
        "    labels_idx = list(range(40))\n",
        "    cm_orig = confusion_matrix(y_true_list, y_pred_list, labels=labels_idx)\n",
        "\n",
        "    \n",
        "    return cm_orig\n",
        "\n",
        "def plot_confusion_matrix_40x40(cm_orig, subset_name):\n",
        "    \"\"\"Plot the full 40x40 confusion matrix in original index order.\"\"\"\n",
        "    display_labels = [make_display_label(INDEX_TO_CHAR[i]) for i in range(40)]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(16, 14))\n",
        "    sns.heatmap(\n",
        "        cm_orig,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        xticklabels=display_labels,\n",
        "        yticklabels=display_labels,\n",
        "        ax=ax,\n",
        "        annot_kws={'size': 7}\n",
        "    )\n",
        "\n",
        "    ax.xaxis.set_label_position('top')\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_xlabel('Predicted', fontsize=12)\n",
        "    ax.set_ylabel('True', fontsize=12)\n",
        "    ax.set_title(\n",
        "        f'{subset_name} Confusion Matrix (40 classes, raw counts)',\n",
        "        fontsize=14,\n",
        "        pad=40\n",
        "    )\n",
        "\n",
        "    plt.xticks(rotation=45, ha='right', fontsize=8)\n",
        "    plt.yticks(rotation=0, fontsize=8)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4. Local distance‑ordered view: anchor + 6 closest neighbours\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def plot_anchor_with_closest_neighbours(cm_orig, anchor_char, subset_name, k_neighbours=6):\n",
        "    \"\"\"\n",
        "    For a given anchor_char, find its k_neighbours closest keys (by keyboard distance),\n",
        "    and plot a confusion submatrix over [anchor + neighbours] in distance order\n",
        "    (anchor first, then increasing distance). Also return that neighbour list.\n",
        "    \"\"\"\n",
        "    if anchor_char not in FULL_COORDS:\n",
        "        raise ValueError(f'No coords for anchor_char {anchor_char!r}')\n",
        "\n",
        "    # char <-> index\n",
        "    char_to_idx = {ch: idx for idx, ch in INDEX_TO_CHAR.items()}\n",
        "\n",
        "    # sort all other chars by distance from anchor\n",
        "    others = [ch for ch in ALL_CHARS if ch != anchor_char]\n",
        "    others_sorted = sorted(others, key=lambda ch: key_distance(anchor_char, ch))\n",
        "\n",
        "    # take closest k_neighbours\n",
        "    closest_chars = others_sorted[:k_neighbours]\n",
        "\n",
        "    # final ordered list: anchor first, then neighbours\n",
        "    ordered_chars = [anchor_char] + closest_chars\n",
        "    ordered_indices = [char_to_idx[ch] for ch in ordered_chars]\n",
        "    ordered_display = [make_display_label(ch) for ch in ordered_chars]\n",
        "\n",
        "    # submatrix of cm_orig\n",
        "    cm_sub = cm_orig[ordered_indices][:, ordered_indices]\n",
        "\n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    sns.heatmap(\n",
        "        cm_sub,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        xticklabels=ordered_display,\n",
        "        yticklabels=ordered_display,\n",
        "        ax=ax,\n",
        "        annot_kws={'size': 10}\n",
        "    )\n",
        "\n",
        "    ax.xaxis.set_label_position('top')\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_xlabel('Predicted', fontsize=12)\n",
        "    ax.set_ylabel('True', fontsize=12)\n",
        "    ax.set_title(\n",
        "        f'{subset_name}: \"{anchor_char}\" + {k_neighbours} closest keys',\n",
        "        fontsize=14,\n",
        "        pad=40\n",
        "    )\n",
        "\n",
        "    plt.xticks(rotation=45, ha='right', fontsize=9)\n",
        "    plt.yticks(rotation=0, fontsize=9)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return closest_chars, cm_sub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Keyboard Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "def plot_virtual_keyboard_heatmap(cm_orig, anchor_char, subset_name):\n",
        "\n",
        "    char_to_idx = {ch: idx for idx, ch in INDEX_TO_CHAR.items()}\n",
        "    if anchor_char not in char_to_idx:\n",
        "        raise ValueError(f'Unknown anchor_char {anchor_char!r}')\n",
        "\n",
        "    i_anchor = char_to_idx[anchor_char]\n",
        "    row = cm_orig[i_anchor].astype(float)  # length 40\n",
        "\n",
        "    values = {INDEX_TO_CHAR[i]: row[i] for i in range(40)}\n",
        "\n",
        "    all_vals = np.array(list(values.values()))\n",
        "    vmax = all_vals.max() if np.any(all_vals > 0) else 1.0\n",
        "    norm = mcolors.Normalize(vmin=0, vmax=vmax)\n",
        "    cmap = plt.cm.Reds\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "    key_width = 0.8\n",
        "    key_height = 0.8\n",
        "\n",
        "    for ch, (x, y) in KEY_COORDS.items():\n",
        "        v = values.get(ch, 0.0)\n",
        "        color = cmap(norm(v)) if v > 0 else (0.9, 0.9, 0.9, 1.0)\n",
        "        rect = plt.Rectangle(\n",
        "            (x - key_width/2, y - key_height/2),\n",
        "            key_width,\n",
        "            key_height,\n",
        "            edgecolor='k',\n",
        "            facecolor=color,\n",
        "            zorder=2\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x, y, ch.upper(), ha='center', va='center', fontsize=10, zorder=3)\n",
        "\n",
        "    for ch, (x, y) in SPECIAL_COORDS.items():\n",
        "        if ch == ' ':\n",
        "            continue\n",
        "        v = values.get(ch, 0.0)\n",
        "        color = cmap(norm(v)) if v > 0 else (0.9, 0.9, 0.9, 1.0)\n",
        "        label = {'\\n': 'ENT', '\\b': 'BS', '\\t': 'TAB'}.get(ch, ch)\n",
        "        rect = plt.Rectangle(\n",
        "            (x - key_width/2, y - key_height/2),\n",
        "            key_width,\n",
        "            key_height,\n",
        "            edgecolor='k',\n",
        "            facecolor=color,\n",
        "            zorder=2\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x, y, label, ha='center', va='center', fontsize=9, zorder=3)\n",
        "\n",
        "    xs = [p[0] for p in SPACE_ANCHORS]\n",
        "    y_space = SPACE_ANCHORS[0][1]\n",
        "    x_min, x_max = min(xs) - 0.4, max(xs) + 0.4\n",
        "    space_width = x_max - x_min\n",
        "    space_height = 0.8\n",
        "\n",
        "    v_space = values.get(' ', 0.0)\n",
        "    color_space = cmap(norm(v_space)) if v_space > 0 else (0.9, 0.9, 0.9, 1.0)\n",
        "\n",
        "    space_rect = plt.Rectangle(\n",
        "        (x_min, y_space - space_height/2),\n",
        "        space_width,\n",
        "        space_height,\n",
        "        edgecolor='k',\n",
        "        facecolor=color_space,\n",
        "        zorder=1\n",
        "    )\n",
        "    ax.add_patch(space_rect)\n",
        "    ax.text((x_min + x_max) / 2, y_space, 'SP', ha='center', va='center', fontsize=10, zorder=3)\n",
        "\n",
        "    # Highlight anchor with thick border\n",
        "    def outline_anchor(ch, lw=2.5, color='blue'):\n",
        "        if ch == ' ':\n",
        "            outline = plt.Rectangle(\n",
        "                (x_min, y_space - space_height/2),\n",
        "                space_width,\n",
        "                space_height,\n",
        "                fill=False,\n",
        "                edgecolor=color,\n",
        "                linewidth=lw,\n",
        "                zorder=4\n",
        "            )\n",
        "            ax.add_patch(outline)\n",
        "        elif ch in KEY_COORDS:\n",
        "            x, y = KEY_COORDS[ch]\n",
        "            outline = plt.Rectangle(\n",
        "                (x - key_width/2, y - key_height/2),\n",
        "                key_width,\n",
        "                key_height,\n",
        "                fill=False,\n",
        "                edgecolor=color,\n",
        "                linewidth=lw,\n",
        "                zorder=4\n",
        "            )\n",
        "            ax.add_patch(outline)\n",
        "        elif ch in SPECIAL_COORDS:\n",
        "            x, y = SPECIAL_COORDS[ch]\n",
        "            outline = plt.Rectangle(\n",
        "                (x - key_width/2, y - key_height/2),\n",
        "                key_width,\n",
        "                key_height,\n",
        "                fill=False,\n",
        "                edgecolor=color,\n",
        "                linewidth=lw,\n",
        "                zorder=4\n",
        "            )\n",
        "            ax.add_patch(outline)\n",
        "\n",
        "    outline_anchor(anchor_char)\n",
        "\n",
        "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
        "    sm.set_array([])\n",
        "    cbar = fig.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
        "    cbar.set_label('Predicted count')\n",
        "\n",
        "    ax.set_aspect('equal', 'box')\n",
        "    ax.set_xlim(-1.0, 13.0)\n",
        "    ax.set_ylim(-1, 5.0)\n",
        "    ax.invert_yaxis()\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_title(f'GIK Keyboard Heatmap Prediction when True Key = \"{anchor_char}\", {subset_name} set',\n",
        "                 fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Set Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm_orig = compute_confusion_matrix_40x40(trainer.test_dataset, model, DEVICE)\n",
        "\n",
        "#plot_confusion_matrix_40x40(cm_orig, 'Test')\n",
        "\n",
        "plot_virtual_keyboard_heatmap(cm_orig, 'd', 'Test')\n",
        "\n",
        "neighbours_a, cm_a = plot_anchor_with_closest_neighbours(cm_orig, 'a', 'Test', k_neighbours=12)\n",
        "\n",
        "neighbours_g, cm_g = plot_anchor_with_closest_neighbours(cm_orig, 'g', 'Test', k_neighbours=20)\n",
        "\n",
        "neighbours_l, cm_l = plot_anchor_with_closest_neighbours(cm_orig, 'l', 'Test', k_neighbours=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm_orig_val = compute_confusion_matrix_40x40(trainer.val_dataset, model, DEVICE)\n",
        "\n",
        "#plot_confusion_matrix_40x40(cm_orig, 'Test')\n",
        "\n",
        "plot_virtual_keyboard_heatmap(cm_orig_val, 'r', 'Validation')\n",
        "\n",
        "neighbours_a_val, cm_a_val = plot_anchor_with_closest_neighbours(cm_orig_val, 'd', 'Validation', k_neighbours=12)\n",
        "\n",
        "neighbours_g_val, cm_g_val = plot_anchor_with_closest_neighbours(cm_orig_val, 'g', 'Validation', k_neighbours=20)\n",
        "\n",
        "neighbours_l_val, cm_l_val = plot_anchor_with_closest_neighbours(cm_orig_val, 'l', 'Validation', k_neighbours=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MODEL_PATH = os.path.join(DATA_DIR, \"gik_model.pt\")\n",
        "# torch.save({\n",
        "#     'model_state_dict': model.state_dict(),\n",
        "#     'config': CONFIG,\n",
        "#     'input_dim': dataset.input_dim,\n",
        "#     'metadata': metadata\n",
        "# }, MODEL_PATH)\n",
        "# print(f\"Model saved to {MODEL_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
